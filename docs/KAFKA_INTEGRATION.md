# Kafka Entegrasyonu

## ğŸ¯ AmaÃ§

BÃ¼yÃ¼k veri akÄ±ÅŸlarÄ±nÄ± (1000 tenant, 3M+ Ã¼rÃ¼n) yÃ¶netmek iÃ§in Kafka entegrasyonu eklendi. Hybrid yaklaÅŸÄ±m kullanÄ±lÄ±yor: **RabbitMQ** basit event'ler iÃ§in, **Kafka** high-volume event'ler iÃ§in.

## ğŸ“Š Mimari

### Event Routing Stratejisi

**Kafka'ya Giden Event'ler (High-Volume):**
- `ProductCreatedEvent`
- `ProductUpdatedEvent`
- `ProductDeletedEvent`
- `ProductStockChangedEvent`
- `OrderCreatedEvent`
- `OrderPaidEvent`
- `OrderStatusChangedEvent`

**RabbitMQ'ya Giden Event'ler (Basit/Low-Latency):**
- DiÄŸer tÃ¼m event'ler (notification'lar, basit iÅŸlemler)

### Kafka AvantajlarÄ±

1. **High Throughput**: Saniyede milyonlarca mesaj iÅŸleyebilir
2. **Event Replay**: Meilisearch index'i yeniden oluÅŸturma, analytics iÃ§in
3. **Partitioning**: Tenant bazlÄ± partition (her tenant'Ä±n event'leri aynÄ± partition'da)
4. **Consumer Groups**: Paralel iÅŸleme (birden fazla consumer instance)
5. **Durability**: Event'ler kaybolmaz, 7 gÃ¼n retention

## ğŸ”§ KonfigÃ¼rasyon

### appsettings.json

```json
{
  "Kafka": {
    "BootstrapServers": "localhost:9092",
    "TopicPrefix": "tinisoft",
    "ConsumerGroup": "tinisoft-consumers"
  },
  "RabbitMQ": {
    "HostName": "localhost",
    "Port": "5672",
    "UserName": "guest",
    "Password": "guest",
    "ExchangeName": "tinisoft_events"
  }
}
```

### Docker Compose

Kafka ve Zookeeper otomatik olarak baÅŸlatÄ±lÄ±r:

```bash
docker-compose up -d
```

## ğŸ“¦ Kafka Topics

Otomatik oluÅŸturulan topic'ler:

- `tinisoft.products` - Product event'leri
- `tinisoft.orders` - Order event'leri
- `tinisoft.inventory` - Stock/Inventory event'leri
- `tinisoft.events` - Default topic (diÄŸer event'ler)

Her topic **3 partition** ile oluÅŸturulur (tenant bazlÄ± load balancing iÃ§in).

## ğŸ”„ Consumer Ä°ÅŸlemleri

`KafkaConsumerService` (Background Service) ÅŸu iÅŸlemleri yapar:

1. **Product Events**:
   - `ProductDeletedEvent` â†’ Meilisearch'ten sil
   - `ProductCreatedEvent` / `ProductUpdatedEvent` â†’ Log (Meilisearch zaten handler'da index ediyor)

2. **Stock Events**:
   - `ProductStockChangedEvent` â†’ Cache invalidation (product cache'i temizle)

3. **Order Events**:
   - Log (ileride analytics, notification iÃ§in kullanÄ±labilir)

## ğŸš€ KullanÄ±m

Kod deÄŸiÅŸikliÄŸi **gerekmez**. Mevcut `IEventBus` kullanÄ±mÄ± aynÄ± kalÄ±r:

```csharp
await _eventBus.PublishAsync(new ProductCreatedEvent
{
    ProductId = product.Id,
    TenantId = tenantId,
    Title = product.Title,
    SKU = product.SKU
}, cancellationToken);
```

`HybridEventBus` otomatik olarak event'i doÄŸru yere yÃ¶nlendirir.

## ğŸ“ˆ Performans

### Kafka Producer AyarlarÄ±

- **Compression**: Snappy (yÃ¼ksek throughput)
- **Batch Size**: 16KB
- **Linger**: 10ms (batch iÃ§in bekleme)
- **Idempotence**: Enabled (duplicate Ã¶nleme)
- **Acks**: All (tÃ¼m replica'larÄ±n onayÄ±)

### Kafka Consumer AyarlarÄ±

- **Auto Offset Reset**: Earliest (ilk mesajdan baÅŸla)
- **Enable Auto Commit**: False (manuel commit - iÅŸlem baÅŸarÄ±lÄ± olursa commit)
- **Max Poll Interval**: 5 dakika

## ğŸ” Monitoring

### Kafka Topics Kontrol

```bash
# Kafka container'a gir
docker exec -it tinisoft-kafka-1 bash

# Topic'leri listele
kafka-topics --bootstrap-server localhost:9092 --list

# Topic detaylarÄ±
kafka-topics --bootstrap-server localhost:9092 --describe --topic tinisoft.products

# Consumer group durumu
kafka-consumer-groups --bootstrap-server localhost:9092 --group tinisoft-consumers --describe
```

### Log Monitoring

Consumer iÅŸlemleri log'lanÄ±r:

```
[Information] Event published to Kafka: ProductCreatedEvent - {EventId} to topic tinisoft.products partition 0 offset 12345
[Information] Product created event received: ProductId: {ProductId}, TenantId: {TenantId}
```

## ğŸ¯ Senaryolar

### Senaryo 1: 1000 Tenant, Her Biri 1000 ÃœrÃ¼n

**Kafka ile:**
- Product event'leri Kafka'ya gider
- Partitioning sayesinde load daÄŸÄ±tÄ±lÄ±r
- Consumer'lar paralel iÅŸler
- Meilisearch indexing background'da yapÄ±lÄ±r
- **SonuÃ§**: Sistem stabil, performans yÃ¼ksek

### Senaryo 2: Cold Start (Cache BoÅŸ)

**Kafka ile:**
- Event'ler Kafka'da saklanÄ±r (7 gÃ¼n)
- Ä°htiyaÃ§ halinde replay edilebilir
- Meilisearch index'i yeniden oluÅŸturulabilir
- **SonuÃ§**: Data kaybÄ± yok, recovery mÃ¼mkÃ¼n

### Senaryo 3: Meilisearch Index Yeniden OluÅŸturma

```bash
# Kafka'dan tÃ¼m product event'lerini replay et
# (Ä°leride implement edilecek)
```

## ğŸ” GÃ¼venlik

Production'da:

1. **SASL/SSL**: Kafka'ya authentication ekle
2. **ACLs**: Topic'lere eriÅŸim kontrolÃ¼
3. **Encryption**: Mesaj ÅŸifreleme (TLS)

## ğŸ“ Notlar

- Kafka **opsiyonel**: Sadece `Kafka:BootstrapServers` set edilirse aktif olur
- RabbitMQ **fallback**: Kafka yoksa RabbitMQ kullanÄ±lÄ±r
- **Hybrid mode**: Her ikisi de varsa otomatik routing yapÄ±lÄ±r
- Consumer **background service**: Uygulama baÅŸladÄ±ÄŸÄ±nda otomatik Ã§alÄ±ÅŸÄ±r

## ğŸ› Troubleshooting

### Kafka baÄŸlantÄ± hatasÄ±

```
Error: Kafka producer error: Connection refused
```

**Ã‡Ã¶zÃ¼m**: Kafka container'Ä±nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin ol:
```bash
docker-compose ps kafka
```

### Consumer mesaj iÅŸlemiyor

**Kontrol**:
1. Consumer group durumunu kontrol et
2. Log'larda hata var mÄ± bak
3. Topic'te mesaj var mÄ± kontrol et

### Partition imbalance

**Ã‡Ã¶zÃ¼m**: TenantId bazlÄ± partition key kullanÄ±lÄ±yor, bu normal. Ä°htiyaÃ§ halinde partition sayÄ±sÄ±nÄ± artÄ±r.

